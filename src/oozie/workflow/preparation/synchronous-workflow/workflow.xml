<workflow-app xmlns="uri:oozie:workflow:0.5" name="SparkPythonPreparation">
          <start to="spark-node-dq" />
          <action name="spark-node-dq">
            <spark xmlns="uri:oozie:spark-action:0.1">
              <job-tracker>${jobTracker}</job-tracker>
              <name-node>${nameNode}</name-node>
              <master>${master}</master>
              <name>Python-Spark-DataQuality</name>
              <jar>${nameNode}/user/root/oozie/apps/tv-audience/workflow/preparation/synchronous-workflow/dq.py</jar>
			  <spark-opts>--driver-memory 512m --executor-memory 512m --num-executors 3 --executor-cores 1</spark-opts>
            </spark>
            <ok to="spark-node" />
            <error to="fail" />
          </action>
          <action name="spark-node">
            <spark xmlns="uri:oozie:spark-action:0.1">
              <job-tracker>${jobTracker}</job-tracker>
              <name-node>${nameNode}</name-node>
              <master>${master}</master>
              <name>Python-Spark-Preparation</name>
              <jar>${nameNode}/user/root/oozie/apps/tv-audience/workflow/preparation/synchronous-workflow/preparation.py</jar>
			  <spark-opts>--driver-memory 512m --executor-memory 512m --num-executors 3 --executor-cores 1</spark-opts>
            </spark>
            <ok to="dataset_preparation" />
            <error to="fail" />
          </action>
          <action name="dataset_preparation">
			<fs>
				<touchz path="${appBaseDirDS}/preparation/synchronous-workflow/${runDate}/_SUCCESS"></touchz>
			</fs>
			<ok to="end"/>
			<error to="fail"/>
		  </action>
          <kill name="fail">
            <message>Workflow failed, error message [${wf:errorMessage(wf:lastErrorNode())}]</message>
          </kill>
          <end name="end" />
 </workflow-app>